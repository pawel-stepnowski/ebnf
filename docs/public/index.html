<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="default.css">
    <link rel="stylesheet" href="http://localhost/cdn/ps-ebnf/default.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css" rel="stylesheet">
    <script type="importmap">
        {
          "imports": {
            "@liquescens/ebnf-types": "http://localhost/cdn/ps-ebnf/index.js"
          }
        }
    </script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-typescript.js"></script>
    <script type="module" src="main.js"></script>
    
</head>
<body>
  <section>
      <h2>Basic usage</h2>
      <h3>ECMAScript 6</h3>
      <pre><!-- @prism(src/index.template.parts.html, basic-usage-importmap) --><code class="language-html">&lt;html&gt;&#13;&#10;&lt;head&gt;&#10;    &lt;link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@liquescens/ebnf/default.css"&gt;&#10;    &lt;script type="importmap"&gt;&#10;        {&#10;            "imports":&#10;            {&#10;                "@liquescens/ebnf-types": "https://cdn.jsdelivr.net/npm/@liquescens/ebnf/index.js",&#10;            }&#10;        }&#10;    &lt;/script&gt;&#10;&lt;/head&gt;&#13;&#10;&lt;/html&gt;</code></pre>
      <pre><!-- @prism(src/index.template.parts.html, basic-usage-types) --><code class="language-typescript">npm install @liquescens/ebnf-types</code></pre>
      <pre><!-- @prism(public/js/examples/basic-usage-parse.js) --><code class="language-typescript">import * as EBNF from '@liquescens/ebnf-types';&#13;&#10;&#13;&#10;/**&#13;&#10; * @param {string} grammar_text&#13;&#10; */&#13;&#10;export function parse(grammar_text)&#13;&#10;{&#13;&#10;    const lexer_configuration = EBNF.LexerConfiguration.iso_14977();&#13;&#10;    const lexer = new EBNF.Lexer(grammar_text, lexer_configuration);&#13;&#10;    const grammar = new EBNF.Parser(lexer).parse();&#13;&#10;    return grammar;&#13;&#10;}&#13;&#10;</code></pre>
      <div class="example-with-output">
        <pre><!-- @prism(public/js/examples/basic-usage-render.js) --><code class="language-typescript">import { DomGenerator } from "@liquescens/ebnf-types/utilities/DomGenerator.js";&#13;&#10;import { parse } from "./basic-usage-parse.js";&#13;&#10;&#13;&#10;const grammar_text = `digit = "0" | "1";&#13;&#10;number = digit, { digit };&#13;&#10;sum = number, "+", number;&#13;&#10;mul = sum, "*", sum;`;&#13;&#10;const grammar = parse(grammar_text);&#13;&#10;&#13;&#10;const current_section = window.page.section(import.meta);&#13;&#10;current_section?.append(new DomGenerator().generate(grammar));&#13;&#10;current_section?.appendPreformattedText(grammar.toString());</code></pre>
        <div><!-- @output(/js/examples/basic-usage-render.js) --><script type="module" src="/js/examples/basic-usage-render.js?section=output_0" id="output_0"></script></div>
      </div>
      <h3>Node.js</h3>
  </section>
  <section>
      <h2>Cookbook</h2>
      <section>
        <h3>Formatting</h3>
        <section>
          <h4>Removing whitespaces</h4>
          <div class="code-with-output">
          </div>
        </section>
      </section>
  </section>
  <section>
      <h2>EBNF variations</h2>
      <div>O generatorze</div>
      <section>
        <h3>Pascal-like (Wikipedia)</h3>
        <!-- <pre> @prism(public/grammars/wikipedia/pascal-like.ebnf.txt) </pre> -->
        <div class="example-with-output">
          <pre><!-- @prism(public/js/examples/variations-pascal.js) --><code class="language-typescript">import * as EBNF from '@liquescens/ebnf-types';&#13;&#10;&#13;&#10;const identifier_pattern = `[a-zA-Z][^'"=,|()\\[\\]{}\\-.;]*`;&#13;&#10;const lexer_configuration = EBNF.LexerConfiguration.iso_14977();&#13;&#10;lexer_configuration.patterns.identifier = { pattern: identifier_pattern };&#13;&#10;const grammar_url = '/grammars/wikipedia/pascal-like.ebnf.txt';&#13;&#10;const grammar_text = await (await fetch(grammar_url)).text();&#13;&#10;const lexer = new EBNF.Lexer(grammar_text, lexer_configuration);&#13;&#10;const grammar = new EBNF.Parser(lexer).parse();&#13;&#10;&#13;&#10;const current_section = window.page.section(import.meta);&#13;&#10;current_section?.append(new EBNF.Utilities.DomGenerator().generate(grammar));</code></pre>
          <div><!-- @output(/js/examples/variations-pascal.js) --><script type="module" src="/js/examples/variations-pascal.js?section=output_1" id="output_1"></script></div>
        </div>
      </section>
      <section>
        <h3>Postal address (Wikipedia)</h3>
        <!-- <pre> @prism(public/grammars/wikipedia/postal-address.bnf.txt) </pre> -->
        <div class="example-with-output">
          <pre><!-- @prism(public/js/examples/variations-postal-address.js) --><code class="language-typescript">import * as EBNF from '@liquescens/ebnf-types';&#13;&#10;&#13;&#10;class BNFParser extends EBNF.Parser&#13;&#10;{&#13;&#10;    static lexerConfiguration()&#13;&#10;    {&#13;&#10;        const configuration = EBNF.LexerConfiguration.iso_14977();&#13;&#10;        configuration.patterns.identifier = { pattern: `&lt;[^&gt;]+&gt;` };&#13;&#10;        configuration.patterns.identifier_beginning = { pattern: `&lt;` };&#13;&#10;        configuration.patterns.defining = { pattern: '::=' };&#13;&#10;        const characters_1 = '[a-zA-Z0-9,=|/!)\\]}\\-\"*?(\\[{;. :+_%@&amp;#\\$&lt;&gt;\\\\\\^`~]|\\*\\)|/\\)|:\\)|\\(/|\\(:';&#13;&#10;        const characters_2 = '[a-zA-Z0-9,=|/!)\\]}\\-\'*?(\\[{;. :+_%@&amp;#\\$&lt;&gt;\\\\\\^`~]|\\*\\)|/\\)|:\\)|\\(/|\\(:';&#13;&#10;        const pattern_1 = `(?<start>\')(?<text>(${characters_1})*)(?<end>\')`;&#13;&#10;        const pattern_2 = `(?<start>\")(?<text>(${characters_2})*)(?<end>\")`;&#13;&#10;        configuration.patterns.terminal_string = { pattern: `${pattern_1}|${pattern_2}` };&#13;&#10;        return configuration;&#13;&#10;    }&#13;&#10;&#13;&#10;    /** @override */&#13;&#10;    _parseDefinition()&#13;&#10;    {&#13;&#10;        const { items: definitions } = this._parseList(() =&gt; this._parseTerm());&#13;&#10;        return new EBNF.Tree.Definition(definitions);&#13;&#10;    }&#13;&#10;&#13;&#10;    /**&#13;&#10;     * @override&#13;&#10;     * @template {EBNF.KeysMatchingType<ebnf.lexertokentypemap, ebnf.tree.token="" |="" ebnf.tree.integer="">} T&#13;&#10;     * @param {T} symbol_name&#13;&#10;     * @returns {EBNF.LexerTokenTypeMap[T]}&#13;&#10;     */&#13;&#10;    _parseTerminal(symbol_name)&#13;&#10;    {&#13;&#10;        if (symbol_name === 'terminator')&#13;&#10;        {&#13;&#10;            const gap = this._parseGap();&#13;&#10;            const terminator = new EBNF.Tree.Token('');&#13;&#10;            terminator.gap.push(...gap.map(item =&gt; item.value));&#13;&#10;            return terminator;&#13;&#10;        }&#13;&#10;        return super._parseTerminal(symbol_name);&#13;&#10;    }&#13;&#10;    &#13;&#10;    /**&#13;&#10;     * @template {EBNF.Tree.Factor | EBNF.Tree.Identifier | EBNF.Tree.BracketedSequence | EBNF.Tree.SpecialSequence | EBNF.Tree.InfixTerm} T&#13;&#10;     * @param {() =&gt; T} parseItem &#13;&#10;     * @returns {{ items: T[] }}&#13;&#10;     */&#13;&#10;    _parseList(parseItem)&#13;&#10;    {&#13;&#10;        const item = parseItem();&#13;&#10;        const items = [item];&#13;&#10;        while (true)&#13;&#10;        {&#13;&#10;            if (this._isListTerminator()) break;&#13;&#10;            const item = parseItem();&#13;&#10;            items.push(item);&#13;&#10;        }&#13;&#10;        return { items };&#13;&#10;    }&#13;&#10;&#13;&#10;    _isListTerminator()&#13;&#10;    {&#13;&#10;        const token_1_gap = this._parseGap();&#13;&#10;        const token_1 = this.lexer.pop();&#13;&#10;        if (!token_1) return true;&#13;&#10;        const result = token_1.name === 'terminator' || token_1.name === 'definition_separator' ? true &#13;&#10;            : token_1.name !== 'identifier' ? false : undefined;&#13;&#10;        if (result !== undefined)&#13;&#10;        {&#13;&#10;            this.lexer.undo(...token_1_gap, token_1);&#13;&#10;            return result;&#13;&#10;        }&#13;&#10;        const token_2_gap = this._parseGap();&#13;&#10;        const token_2 = this.lexer.top();&#13;&#10;        this.lexer.undo(...token_1_gap, token_1, ...token_2_gap);&#13;&#10;        return token_2?.name === 'defining';&#13;&#10;    }&#13;&#10;}&#13;&#10;&#13;&#10;try&#13;&#10;{&#13;&#10;    const grammar_text = await (await fetch('/grammars/wikipedia/postal-address.bnf.txt')).text();&#13;&#10;    const lexer = new EBNF.Lexer(grammar_text, BNFParser.lexerConfiguration());&#13;&#10;    const grammar = new BNFParser(lexer).parse();&#13;&#10;    &#13;&#10;    window.page.section(import.meta)?.append(new EBNF.Utilities.DomGenerator().generate(grammar));&#13;&#10;    window.page.section(import.meta)?.append(Object.assign(document.createElement('div'), { style: 'white-space: pre;', textContent: grammar.toString() }));&#13;&#10;}&#13;&#10;catch (e)&#13;&#10;{&#13;&#10;    window.page.section(import.meta)?.append(Object.assign(document.createElement('div'), { style: 'white-space: pre;', textContent: e?.toString() }));&#13;&#10;}&#13;&#10;</ebnf.lexertokentypemap,></end></text></start></end></text></start></code></pre>
          <div><!-- @output(/js/examples/variations-postal-address.js) --><script type="module" src="/js/examples/variations-postal-address.js?section=output_2" id="output_2"></script></div>
        </div>
      </section>
  </section>

</body></html>